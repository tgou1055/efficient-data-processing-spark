1. 7-3.sql on joins: WARN LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.
2. 7-3.sql ERROR CodeGenerator: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 120, Colum
n 9: Redefinition of local variable "smj_isNull_7"
3. WARN HiveMetaStore: Location: file:/opt/spark/work-dir/spark-warehouse/tpch.db/part specified for non-external table:part
4.  WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
5. 23/12/09 16:20:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
6. [657.907s][warning][gc,alloc] Executor task launch worker for task 1.0 in stage 34.0 (TID 96): Retried waiting for GCLocker too often allocating
 8388610 words
23/12/09 16:33:11 WARN TaskMemoryManager: Failed to allocate a page (67108864 bytes), try again.
23/12/09 16:33:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
7. proper data types for tpch tables.   
8. 23/12/10 01:42:12 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
9. 23/12/10 01:45:45 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
23/12/10 01:45:51 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `minio`.`lineitem_w_encoding_w_partitioning` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
10. 23/12/10 16:11:41 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider CSV. Persisting data source table `minio`.`lineitem_wo_encoding` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
11. 23/12/10 16:33:19 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier    
12. 23/12/10 16:34:17 WARN log: Updating partition stats fast for: lineitem_w_encoding_w_partitioning
23/12/10 16:34:17 WARN log: Updating partition stats fast for: lineitem_w_encoding_w_partitioning
23/12/10 16:34:17 WARN log: Updated size to 25673217
13. 23/12/21 03:09:50 ERROR CodeGenerator: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 105, Column 9: Redefinition of local variable "smj_isNull_7" 
org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 105, Column 9: Redefinition of local variable "smj_isNull_7"    
14. 23/12/21 11:47:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.